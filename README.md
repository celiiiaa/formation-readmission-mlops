# ðŸŽ“ Examen MLOps - Sup de Vinci 2025 


## Objectif
PrÃ©dire les rÃ©admissions hospitaliÃ¨res avec un modÃ¨le XGBoost, suivi et dÃ©ployÃ© avec MLflow et FastAPI.

## Structure
- `train.py` : entraÃ®nement du modÃ¨le + MLflow
- `app/` : API FastAPI
- `src/` : wrapper pour charger le modÃ¨le
- `data/` : jeu de donnÃ©es TSV
- `MLproject` + `requirements.txt` : exÃ©cution avec MLflow

### Choix des hyperparamÃ¨tres

Une recherche en grille a Ã©tÃ© rÃ©alisÃ©e sur deux hyperparamÃ¨tres clÃ©s de XGBoost :

- **`max_depth`** : dÃ©finit la profondeur maximale des arbres. Deux valeurs ont Ã©tÃ© testÃ©es (3 et 5) afin de comparer un modÃ¨le simple (moins de risque dâ€™overfitting) Ã  un modÃ¨le plus complexe pouvant capturer des interactions plus profondes.

- **`n_estimators`** : contrÃ´le le nombre total dâ€™arbres dans le modÃ¨le. Les valeurs 100 et 200 ont Ã©tÃ© testÃ©es pour comparer la performance dâ€™un modÃ¨le rapide contre un modÃ¨le plus lent mais potentiellement plus performant.

Ces choix ont Ã©tÃ© guidÃ©s par un compromis entre performance, gÃ©nÃ©ralisation et temps de calcul dans un environnement cloud partagÃ©.
Un **grid search manuel** a Ã©tÃ© effectuÃ© sur deux hyperparamÃ¨tres clÃ©s de XGBoost :

| `max_depth` | `n_estimators` |
|-------------|----------------|
| 3           | 100            |
| 3           | 200            |
| 5           | 100            |
| 5           | 200            |

Un total de 4 modÃ¨les ont Ã©tÃ© testÃ©s avec une recherche en grille sur :
- `max_depth` âˆˆ {3, 5}
- `n_estimators` âˆˆ {100, 200}
 
## RÃ©sultat
âœ… Choix final : max_depth = 5, n_estimators = 200

Câ€™est le modÃ¨le le plus performant en accuracy parmi tous les runs : 96.38 %
La profondeur 5 permet au modÃ¨le de capturer des relations non linÃ©aires complexes dans les donnÃ©es, ce qui amÃ©liore la prÃ©cision.
Le fait dâ€™avoir 200 arbres permet une meilleure stabilitÃ© du modÃ¨le, et compense dâ€™Ã©ventuels sous-apprentissages.
## Analyse visuelle :
Dans MLflow, la visualisation en Parallel Coordinates Plot montre que la combinaison max_depth=5 et n_estimators=200 est la seule Ã  atteindre la zone rouge (haut de lâ€™Ã©chelle de prÃ©cision), ce qui confirme numÃ©riquement et visuellement sa supÃ©rioritÃ©.


Bien que ce modÃ¨le soit le plus long Ã  entraÃ®ner (environ 8 minutes), le gain significatif en performance justifie largement ce choix, surtout dans un cadre de production oÃ¹ la performance est prioritaire par rapport au temps dâ€™entraÃ®nement ponctuel.

## API
Lancer avec :
```bash
uvicorn app.main:app --reload


---

## ðŸ§ª EntraÃ®nement & Suivi avec MLflow


### âœ”ï¸ Objectif respectÃ© :
- ðŸ“‰ `mlflow.log_param()` pour les hyperparamÃ¨tres
- ðŸ“ˆ `mlflow.log_metric()` pour `accuracy`
- ðŸ“¦ `mlflow.xgboost.log_model()` avec `signature` et `input_example`
- ðŸ” Comparaison des runs via MLflow UI

### ðŸ“¸ RÃ©sultat du meilleur run :

| max_depth | n_estimators | accuracy |
|-----------|--------------|----------|
| 5         | 200          | **0.9638 âœ…** |

> Le modÃ¨le retenu est enregistrÃ© dans le **Model Registry MLflow** sous le nom `xgb-readmission`, version **5**.

ðŸ‘‰ [AccÃ©der Ã  MLflow UI](https://user-hadji-mlflow.user.lab.sspcloud.fr)

---



---

## ðŸŒ DÃ©ploiement en API REST (FastAPI)

Lâ€™API expose une route `/predict` pour interroger le modÃ¨le dÃ©ployÃ©.

 Tester lâ€™API localement (SSPCloud)
 Sur SSPCloud, le paramÃ¨tre --root-path /proxy/8000 est obligatoire pour que la documentation /docs fonctionne correctement.
### Exemple d'entrÃ©e JSON :

```json
{
  "chol": 3.5,
  "crp": 0.8,
  "phos": 1.4
}
--> PREDICTION 1 

{
  "chol": 9.72,
  "crp": 14.87,
  "phos": 8.48
} 
--> PREDICTION 0

